{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Conv2D, Dense, Flatten, BatchNormalization , Dropout, MaxPooling2D\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of folders - 28\n",
      "folders - ['.DS_Store', 'R', 'U', 'I', 'N', 'G', 'T', 'S', 'A', 'F', 'O', 'H', 'DEL', 'NOTHING', 'SPACE', 'M', 'C', 'D', 'V', 'Q', 'X', 'E', 'B', 'K', 'L', 'Y', 'P', 'W']\n"
     ]
    }
   ],
   "source": [
    "par_dir = \"/Users/ayush/Desktop/images/self data final\"\n",
    "letters = os.listdir(par_dir)\n",
    "print(\"No. of folders - \" + str(len(letters)))\n",
    "print(\"folders - \" + str(letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'O': 13, 'P': 14, 'Q': 15, 'R': 16, 'S': 17, 'T': 18, 'U': 19, 'V': 20, 'W': 21, 'X': 22, 'Y': 23, 'SPACE': 26, 'NOTHING': 27, 'DEL': 28}\n"
     ]
    }
   ],
   "source": [
    "# Labels declaration\n",
    "dict_letter_to_number = {}\n",
    "\n",
    "char_list = 'ABCDEFGHIKLMNOPQRSTUVWXY'\n",
    "\n",
    "for i in range(24):\n",
    "    dict_letter_to_number[char_list[i]] = i\n",
    "\n",
    "dict_letter_to_number['SPACE'] = 26\n",
    "dict_letter_to_number['NOTHING'] = 27\n",
    "dict_letter_to_number['DEL'] = 28\n",
    "\n",
    "print(dict_letter_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dataset created\n"
     ]
    }
   ],
   "source": [
    "img_data = []\n",
    "\n",
    "for letter in letters:\n",
    "    \n",
    "    if letter == '.DS_Store' :\n",
    "        continue\n",
    "    \n",
    "    letter_dir = os.path.join(par_dir, letter)\n",
    "    images_path_list = os.listdir(letter_dir)\n",
    "    \n",
    "    for image_index in range(len(images_path_list)):\n",
    "        \n",
    "        img_path = os.path.join(letter_dir, images_path_list[image_index])\n",
    "        \n",
    "        if not img_path.endswith(\".jpg\") :\n",
    "            continue\n",
    "            \n",
    "        img = cv.imread(img_path, 0)        # grayscale\n",
    "        img = cv.resize(img, (60, 60), interpolation = cv.INTER_AREA)   # resize to (60, 60)\n",
    "        \n",
    "        img_data.append([img, dict_letter_to_number[letter]])\n",
    "            \n",
    "print(\"Image dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(img_data)       # training data shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []         \n",
    "y = []\n",
    "\n",
    "IMG_SIZE = 60\n",
    "\n",
    "for features,label in img_data:\n",
    "    \n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35709, 60, 60, 1) (35709,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,  y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pickle to save the dataset\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load the dataset dataset\n",
    "import pickle\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
